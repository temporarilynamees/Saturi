# Ai-server/model_server.py

import torch
from flask import Flask, request, jsonify, send_file
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import io
import soundfile as sf
import os

# --- VITS ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸ ---
import commons
import utils
from models import SynthesizerTrn
from text import text_to_sequence
# ğŸ’¡ [ìˆ˜ì •] config.json ëŒ€ì‹  text/symbols.pyì—ì„œ symbols ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ê°€ì ¸ì˜µë‹ˆë‹¤.
from text.symbols import symbols

# --- Flask ì•± ì´ˆê¸°í™” ---
app = Flask(__name__)

# --- ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ ---
print("ì„œë²„ ì‹œì‘... ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤.")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ì‚¬ìš© ì¥ì¹˜: {str(device).upper()}")

# --- 1. ë²ˆì—­ ëª¨ë¸ ë¡œë“œ ---
print("ë²ˆì—­ ëª¨ë¸ ë¡œë”© ì¤‘...")
model_dir_std_to_jeju = "./bidirectional_models_gpu/std_to_jeju/"
tokenizer_std_to_jeju = AutoTokenizer.from_pretrained(model_dir_std_to_jeju)
model_std_to_jeju = AutoModelForSeq2SeqLM.from_pretrained(model_dir_std_to_jeju)
model_std_to_jeju.to(device)

model_dir_jeju_to_std = "./bidirectional_models_gpu/jeju_to_std/"
tokenizer_jeju_to_std = AutoTokenizer.from_pretrained(model_dir_jeju_to_std)
model_jeju_to_std = AutoModelForSeq2SeqLM.from_pretrained(model_dir_jeju_to_std)
model_jeju_to_std.to(device)
print("ë²ˆì—­ ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

# --- 2. ì»¤ìŠ¤í…€ VITS ëª¨ë¸ ë¡œë“œ ---
print("ì»¤ìŠ¤í…€ TTS(VITS) ëª¨ë¸ ë¡œë”© ì¤‘...")
config_path = "./vits_models/friend_config.json"
# âš ï¸ vits_model_pathì˜ íŒŒì¼ëª…ì€ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ íŒŒì¼ëª…ìœ¼ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤!
vits_model_path = "./vits_models/G_77000.pth" 

hps = utils.get_hparams_from_file(config_path)

# ğŸ’¡ [ìˆ˜ì •] config.jsonì˜ symbols ëŒ€ì‹ , íŒŒì¼ì—ì„œ ì§ì ‘ ë¶ˆëŸ¬ì˜¨ symbols ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë®ì–´ì”ë‹ˆë‹¤.
hps.symbols = symbols

# ì´ì œ len(symbols)ëŠ” 141ì´ ë˜ì–´ ëª¨ë¸ êµ¬ì¡°ê°€ ì¼ì¹˜í•˜ê²Œ ë©ë‹ˆë‹¤.
net_g = SynthesizerTrn(
    len(symbols),
    hps.data.filter_length // 2 + 1,
    hps.train.segment_size // hps.data.hop_length,
    n_speakers=hps.data.n_speakers,
    **hps.model
).to(device)
_ = net_g.eval()

_ = utils.load_checkpoint(vits_model_path, net_g, None)
print("ì»¤ìŠ¤í…€ TTS(VITS) ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

# --- í…ìŠ¤íŠ¸ë¥¼ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ---
def get_text(text, hps):
    text_norm = text_to_sequence(text, hps.data.text_cleaners)
    if hps.data.add_blank:
        text_norm = commons.intersperse(text_norm, 0)
    text_norm = torch.LongTensor(text_norm)
    return text_norm

# --- ë²ˆì—­ API ---
@app.route('/translate', methods=['POST'])
def handle_translation():
    try:
        data = request.json
        sentence = data['sentence']
        direction = data['direction']
        
        model, tokenizer = (model_std_to_jeju, tokenizer_std_to_jeju) if direction == 'std_to_jeju' else (model_jeju_to_std, tokenizer_jeju_to_std)
        
        input_text = "<s>" + sentence + "</s>"
        inputs = tokenizer(input_text, return_tensors="pt").to(device)

        outputs = model.generate(
            inputs.input_ids, max_length=128, num_beams=5, early_stopping=True
        )
        translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return jsonify({"translation": translated_text})

    except Exception as e:
        print(f"Error during translation: {e}")
        return jsonify({"error": "ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}), 500

# --- [ì‹ ê·œ] VITS TTS ìƒì„± API ---
@app.route('/generate-tts', methods=['POST'])
def handle_vits_tts():
    try:
        data = request.json
        text = data.get('text')
        if not text:
            return jsonify({"error": "text í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # VITS ëª¨ë¸ë¡œ ìŒì„± ìƒì„±
        stn_tst = get_text(text, hps)
        with torch.no_grad():
            x_tst = stn_tst.to(device).unsqueeze(0)
            x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)
            audio = net_g.infer(x_tst, x_tst_lengths, noise_scale=.667, noise_scale_w=0.8, length_scale=1)[0][0,0].data.cpu().float().numpy()

        # ë©”ëª¨ë¦¬ ë²„í¼ì— WAV íŒŒì¼ ìƒì„± í›„ ì „ì†¡
        buffer = io.BytesIO()
        sf.write(buffer, audio, hps.data.sampling_rate, format='WAV')
        buffer.seek(0)
        
        return send_file(buffer, mimetype='audio/wav')

    except Exception as e:
        print(f"Error during VITS TTS generation: {e}")
        return jsonify({"error": "TTS ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}), 500

# --- ì„œë²„ ì‹¤í–‰ ---
if __name__ == '__main__':
    print("ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ. API ìš”ì²­ ëŒ€ê¸° ì¤‘...")
    app.run(host='0.0.0.0', port=8000, debug=False)